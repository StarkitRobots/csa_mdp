#pragma once

#include "starkit_csa_mdp/solvers/black_box_learner.h"

namespace csa_mdp
{
class TreePolicyIteration : public BlackBoxLearner
{
public:
  TreePolicyIteration();
  virtual ~TreePolicyIteration();

  virtual void init(std::default_random_engine* engine) override;
  virtual void update(std::default_random_engine* engine) override;

  virtual void setNbThreads(int nb_threads) override;

  /// Update value function based on current policy
  void updateValue(std::default_random_engine* engine);

  /// Return a new policy based on current value function
  std::unique_ptr<Policy> updatePolicy(std::default_random_engine* engine);

  virtual std::string getClassName() const override;
  virtual Json::Value toJson() const override;
  virtual void fromJson(const Json::Value& v, const std::string& dir_name) override;

protected:
  /// Best expected score reached by a policy at the moment
  double best_score;

  /// Current approximation of the policy function
  std::unique_ptr<Policy> policy;

  /// Current approximation of the value function
  std::unique_ptr<starkit_fa::FunctionApproximator> value;

  /// The approximator used to update the value function
  std::unique_ptr<ValueApproximator> value_approximator;

  /// The optimizer used to train policies
  std::unique_ptr<starkit_fa::OptimizerTrainer> policy_trainer;

  /// If enabled, then memory of the policy_trainer is emptied before each
  /// training process
  bool memoryless_policy_trainer;

  /// Does the learner use an approximation of the value
  bool use_value_approximator;
};

}  // namespace csa_mdp
